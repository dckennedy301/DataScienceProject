<style>
    /* General Styles */
    body {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        background-color: #000000;
        margin: 0;
        color: #ffffff;
        line-height: 1.6;
    }

    /* Navbar Styles */
    #navbar {
        background-color: #0edacf;
        width: 100%;
        position: fixed;
        top: 0;
        left: 0;
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 15px 30px;
        box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);
        z-index: 1000;
    }

    #navbar h1 {
        margin: 0;
        font-size: 24px;
        font-weight: 600;
        color: #000000;
    }

    /* Welcome Section Styles */
    #welcome-section {
        display: flex;
        align-items: center;
        justify-content: center;
        flex-direction: column;
        padding: 120px 10%;
        text-align: center;
        background-color: #111111;
    }

    .welcome-text h1 {
        font-size: 32px;
        color: #0edacf;
        margin-bottom: 40px;
        font-weight: 700;
    }

    .model-description {
        background-color: #1c1c1c;
        padding: 25px;
        border-radius: 12px;
        border: 2px solid #0edacf;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.6);
        margin-top: 30px;
        text-align: left;
        max-width: 800px;
        width: 100%;
    }

    .model-description h2,
    .model-description h3 {
        color: #0edacf;
    }

    .model-description p {
        margin: 12px 0;
        color: #cccccc;
    }

    .model-description p strong {
        color: #0edacf;
    }

    /* Form Styles */
    #upload-form {
        margin-top: 40px;
        padding: 20px;
        background-color: #1c1c1c;
        border-radius: 10px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.6);
        text-align: center;
    }

    input[type="file"] {
        padding: 12px;
        font-size: 16px;
        margin-bottom: 20px;
        border-radius: 6px;
        border: 1px solid #0edacf;
        background-color: #111111;
        color: #ffffff;
        width: 100%;
        max-width: 400px;
    }

    input[type="submit"] {
        background-color: #0edacf;
        color: black;
        padding: 12px 30px;
        border: none;
        border-radius: 6px;
        font-size: 18px;
        cursor: pointer;
        transition: background-color 0.3s ease;
    }

    input[type="submit"]:hover {
        background-color: #0cb2b1;
    }

    /* Result Section Styles */
    #result-section {
        margin-top: 40px;
        padding: 20px;
        background-color: #1c1c1c;
        border-radius: 10px;
        box-shadow: 0 4px 10px rgba(0, 0, 0, 0.6);
        text-align: center;
        color: #ffffff;
        max-width: 800px;
        width: 100%;
    }

    /* Media Queries */
    @media screen and (max-width: 768px) {
        #navbar {
            padding: 10px 20px;
        }

        #navbar h1 {
            font-size: 20px;
        }

        #welcome-section {
            padding: 100px 5%;
        }

        .model-description {
            padding: 20px;
        }
    }
</style>

</head>
<body>
    <!-- Navbar -->
    <nav id="navbar">
        <h1>Dylan's Portfolio - Tumor Type Prediction</h1>
    </nav>

    <!-- Welcome Section -->
    <section id="welcome-section">
        <div class="welcome-text">
            <h1>Overview of my Brain Tumor Detection Project</h1>

            <!-- Model Description Box -->
            <div class="model-description">
                <h2>Detailed Description of the Brain Tumor Detection Model</h2>
                <p>This model is designed to automatically classify brain MRI images into one of four categories: Glioma, Meningioma, No Tumor, and Pituitary Tumor. It is built using the PyTorch deep learning framework and leverages the pre-trained ResNet-50 architecture, known for its robust feature extraction capabilities, especially in image classification tasks.</p>

                <h3>1. Data Preparation and Preprocessing:</h3>
                <p><strong>Dataset Composition:</strong> The model uses two datasets: a training set and a validation set, each containing MRI images categorized into the four classes mentioned above. The datasets are organized using PyTorch’s ImageFolder utility, which expects images to be stored in directories corresponding to their class labels.</p>
                <p><strong>Image Transformation:</strong> Each image is resized to 256x256 pixels to ensure uniformity across the dataset. This step is crucial because it allows the model to process all images at the same scale, important for maintaining consistency during training. After resizing, the images are converted into tensors—a necessary step for feeding them into the neural network.</p>

                <h3>2. Model Architecture:</h3>
                <p><strong>Base Model – ResNet-50:</strong> The model is based on ResNet-50, a deep convolutional neural network pre-trained on the ImageNet dataset, which contains millions of images across thousands of categories. ResNet-50's architecture is known for its depth and the use of residual blocks, which help mitigate the vanishing gradient problem in deep networks.</p>
                <p><strong>Customization for Tumor Classification:</strong> The ResNet-50’s final fully connected layer, initially designed to classify 1,000 classes, is replaced with a layer that outputs predictions for the four tumor classes. The new layer contains four output neurons, each corresponding to one tumor category.</p>

                <h3>3. Training Process:</h3>
                <p><strong>Loss Function:</strong> Cross Entropy Loss is used for multi-class classification, comparing the predicted class probabilities with the actual labels. The model minimizes this loss during training.</p>
                <p><strong>Optimizer:</strong> Adam Optimizer is used for updating the model’s weights during training. Adam adapts learning rates during optimization, leading to faster convergence.</p>
                <p><strong>Training on GPU:</strong> When available, the training leverages a GPU for faster computation, especially when processing large amounts of image data. The model is trained over several epochs.</p>

                <h3>4. Model Evaluation:</h3>
                <p><strong>Validation Set:</strong> The model is evaluated on a validation dataset after each epoch to monitor its performance and how well it generalizes to unseen data.</p>
                <p><strong>Confusion Matrix:</strong> A confusion matrix is generated to highlight correct and incorrect predictions for each class, offering insight into where the model excels or needs improvement.</p>

                <h3>5. Model Deployment:</h3>
                <p>Once the model is trained and evaluated, it can be deployed to a web application where users can upload MRI images for classification. The model outputs the predicted class, helping users identify the type of tumor present.</p>

                <h3>Disclaimer:</h3>
                <p>This brain tumor detection model is trained to classify four types of brain tumors: Glioma, Meningioma, No Tumor, and Pituitary Tumor. It may not provide accurate results for other types of tumors or medical conditions. This model is intended as a supplementary tool and should not replace medical consultation.</p>
            </div>
        </div>

        <h1>Please upload an image, and the model will predict the type of tumor present.</h1>

        <!-- Upload Form -->
        <form id="upload-form" action="/" method="post" enctype="multipart/form-data">
            <input type="file" name="file" accept="image/*" required>
            <br>
            <input type="submit" value="Predict Tumor Type">
        </form>

        <!-- Result Section -->
        {% if prediction %}
        <div id="result-section">
            <h2>Prediction Result:</h2>
            <p>{{ prediction }}</p>
        </div>
        {% endif %}
    </section>
</body>
